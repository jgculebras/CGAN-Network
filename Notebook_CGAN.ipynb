{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rUABChBlZFd"
      },
      "source": [
        "### RED CGAN:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lvnHap9TlZFh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Embedding, multiply\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "# Constants\n",
        "IMG_ROWS, IMG_COLS, CHANNELS = 28, 28, 1\n",
        "IMG_SHAPE = (IMG_ROWS, IMG_COLS, CHANNELS)\n",
        "NOISE_DIM = 100\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape images\n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "# Rescale labels to one-hot vectors\n",
        "y_train = np.eye(NUM_CLASSES)[y_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-CaS9p5GlZFi"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(256, input_dim=NOISE_DIM))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(np.prod(IMG_SHAPE), activation='tanh'))\n",
        "    model.add(Reshape(IMG_SHAPE))\n",
        "\n",
        "    noise = Input(shape=(NOISE_DIM,))\n",
        "    label = Input(shape=(NUM_CLASSES,))\n",
        "    label_embedding = Dense(NOISE_DIM)(label)\n",
        "\n",
        "    model_input = multiply([noise, label_embedding])\n",
        "    img = model(model_input)\n",
        "\n",
        "    return Model([noise, label], img)\n",
        "\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=IMG_SHAPE, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    img = Input(shape=IMG_SHAPE)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iH4OjV__lZFj"
      },
      "outputs": [],
      "source": [
        "# Build the generator\n",
        "generator = build_generator()\n",
        "\n",
        "# Build the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Freeze discriminator's weights during generator training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build the CGAN by connecting generator and discriminator\n",
        "noise = Input(shape=(NOISE_DIM,))\n",
        "label = Input(shape=(NUM_CLASSES,))\n",
        "img = generator([noise, label])\n",
        "validity = discriminator(img)\n",
        "\n",
        "# Compile the CGAN model\n",
        "cgan = Model([noise, label], validity)\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "SAMPLE_INTERVAL = 10\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((BATCH_SIZE, 1))\n",
        "fake = np.zeros((BATCH_SIZE, 1))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Select a random batch of images\n",
        "    idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
        "    real_images = x_train[idx]\n",
        "    labels = y_train[idx]\n",
        "\n",
        "    # Generate a batch of fake images\n",
        "    noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n",
        "    gen_images = generator.predict([noise, labels])\n",
        "\n",
        "    # Train the discriminator\n",
        "    d_loss_real = discriminator.train_on_batch(real_images, valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_images, fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train the generator\n",
        "    noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n",
        "    g_loss = cgan.train_on_batch([noise, labels], valid)\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % SAMPLE_INTERVAL == 0:\n",
        "        print(f\"Epoch {epoch}/{EPOCHS} | Discriminator loss: {d_loss[0]:.4f}, Generator loss: {g_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv-CrJX5pbMq",
        "outputId": "7766a2d4-2c7f-4f33-8840-9d365b6d4f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 381ms/step\n",
            "Epoch 0/200 | Discriminator loss: 0.6992, Generator loss: 0.6336\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Epoch 10/200 | Discriminator loss: 0.3254, Generator loss: 0.2833\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Epoch 20/200 | Discriminator loss: 0.1440, Generator loss: 0.4260\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Epoch 30/200 | Discriminator loss: 0.0109, Generator loss: 1.1474\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Epoch 40/200 | Discriminator loss: 0.0032, Generator loss: 0.5192\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Epoch 50/200 | Discriminator loss: 0.0174, Generator loss: 0.7481\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate synthetic images\n",
        "num_examples = 10\n",
        "noise = np.random.normal(0, 1, (num_examples, NOISE_DIM))\n",
        "labels = np.eye(NUM_CLASSES)[np.arange(num_examples) % NUM_CLASSES]\n",
        "generated_images = generator.predict([noise, labels])\n",
        "\n",
        "# Rescale generated images to [0, 1]\n",
        "generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "# Plot generated images\n",
        "fig, axs = plt.subplots(1, num_examples, figsize=(10, 2))\n",
        "fig.suptitle('Generated Images', fontsize=14, fontweight='bold')\n",
        "for i in range(num_examples):\n",
        "    axs[i].imshow(generated_images[i, :, :, 0], cmap='gray')\n",
        "    axs[i].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nakd1sHeqEoQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}